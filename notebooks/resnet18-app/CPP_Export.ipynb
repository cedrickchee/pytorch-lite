{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a PyTorch Model in C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Converting Your PyTorch Model to Torch Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An instance of your model.\n",
    "model = torchvision.models.resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example input you would normally provide to your model's forward() method.\n",
    "example = torch.rand(1, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.\n",
    "traced_script_module = torch.jit.trace(model, example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = traced_script_module(torch.ones(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0808,  0.5042,  0.7030, -0.9465,  0.4538], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(output[0, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to Torch Script via Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(torch.nn.Module):\n",
    "    def __init__(self, N, M):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.weight = torch.nn.Parameter(torch.rand(N, M))\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.sum() > 0:\n",
    "          output = self.weight.mv(input)\n",
    "        else:\n",
    "          output = self.weight + input\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the `forward` method of this module uses control flow that is dependent on the input, it is not suitable for tracing. Instead, we can convert it to a `ScriptModule` by subclassing it from `torch.jit.ScriptModule` and adding a `@torch.jit.script_method` annotation to the model’s `forward` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(torch.jit.ScriptModule):\n",
    "    def __init__(self, N, M):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.weight = torch.nn.Parameter(torch.rand(N, M))\n",
    "\n",
    "    @torch.jit.script_method\n",
    "    def forward(self, input):\n",
    "        if bool(input.sum() > 0):\n",
    "          output = self.weight.mv(input)\n",
    "        else:\n",
    "          output = self.weight + input\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_script_module = MyModule(2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Serializing Your Script Module to a File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have a `ScriptModule` in your hands, either from tracing or annotating a PyTorch model, you are ready to serialize it to a file. Later on, you’ll be able to load the module from this file in C++ and execute it without any dependency on Python. Say we want to serialize the `ResNet18` model shown earlier in the tracing example. To perform this serialization, simply call save on the module and pass it a filename:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_script_module.save(\"model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will produce a `model.pt` file in your working directory. We have now officially left the realm of Python and are ready to cross over to the sphere of C++."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 45M\r\n",
      "drwxrwxr-x 3 ubuntu ubuntu 4.0K May 11 02:27 .\r\n",
      "drwxrwxr-x 4 ubuntu ubuntu 4.0K May 11 02:26 ..\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  260 May 10 18:16 CMakeLists.txt\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 7.3K May 10 17:48 CPP_Export.ipynb\r\n",
      "drwxrwxr-x 2 ubuntu ubuntu 4.0K May 11 02:26 .ipynb_checkpoints\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  45M May 11 02:27 model.pt\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu  796 May 11 02:14 resnet18-app.cpp\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Loading Your Script Module in C++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load your serialized PyTorch model in C++, your application must depend on the PyTorch C++ API – also known as LibTorch. The LibTorch distribution encompasses a collection of shared libraries, header files and CMake build configuration files. While CMake is not a requirement for depending on LibTorch, it is the recommended approach and will be well supported into the future. For this tutorial, we will be building a minimal C++ application using CMake and LibTorch that simply loads and executes a serialized PyTorch model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Minimal C++ Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#include <torch/script.h> // One-stop header.\r\n",
      "\r\n",
      "#include <iostream>\r\n",
      "#include <memory>\r\n",
      "\r\n",
      "int main(int argc, const char* argv[]) {\r\n",
      "    if (argc != 2) {\r\n",
      "        std::cerr << \"usage: example-app <path-to-exported-script-module>\\n\";\r\n",
      "        return -1;\r\n",
      "    }\r\n",
      "\r\n",
      "    // Deserialize the ScriptModule from a file using torch::jit::load().\r\n",
      "    std::shared_ptr<torch::jit::script::Module> module = torch::jit::load(argv[1]);\r\n",
      "\r\n",
      "    assert(module != nullptr);\r\n",
      "    std::cout << \"ok\\n\";\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat resnet18-app.cpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depending on LibTorch and Building the Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmake_minimum_required(VERSION 3.0 FATAL_ERROR)\r\n",
      "project(custom_ops)\r\n",
      "\r\n",
      "find_package(Torch REQUIRED)\r\n",
      "\r\n",
      "add_executable(resnet18-app resnet18-app.cpp)\r\n",
      "target_link_libraries(resnet18-app \"${TORCH_LIBRARIES}\")\r\n",
      "set_property(TARGET resnet18-app PROPERTY CXX_STANDARD 11)"
     ]
    }
   ],
   "source": [
    "!cat CMakeLists.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we need to build the example application is the LibTorch distribution. You can always grab the latest stable release from the [download page](https://pytorch.org/get-started/locally/#start-locally) on the PyTorch website. If you download and unzip the latest archive, you should receive a folder with the following directory structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 63364\r\n",
      "drwxr-xr-x 6 ubuntu ubuntu     4096 Dec  6 07:14 libtorch\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 64875864 Dec  7 19:14 libtorch-shared-with-deps-1.0.0.zip\r\n",
      "drwxrwxr-x 4 ubuntu ubuntu     4096 May 11 02:26 notebooks\r\n",
      "total 20\r\n",
      "drwxr-xr-x 2 ubuntu ubuntu 4096 Dec  6 07:14 bin\r\n",
      "-rw-r--r-- 1 ubuntu ubuntu    6 Dec  6 07:14 build-version\r\n",
      "drwxr-xr-x 8 ubuntu ubuntu 4096 Dec  6 07:14 include\r\n",
      "drwxr-xr-x 2 ubuntu ubuntu 4096 Dec  6 07:38 lib\r\n",
      "drwxr-xr-x 3 ubuntu ubuntu 4096 Dec  6 07:14 share\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l ../../; ls -l ../../libtorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `lib/` folder contains the shared libraries you must link against,\n",
    "- The `include/` folder contains header files your program will need to include,\n",
    "- The `share/` folder contains the necessary CMake configuration to enable the simple find_package(Torch) command above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is building the application. For this, assume our example directory is laid out like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 45780\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu      260 May 10 18:16 CMakeLists.txt\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu    10519 May 11 02:37 CPP_Export.ipynb\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 46857749 May 11 02:27 model.pt\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu      468 May 11 02:30 resnet18-app.cpp\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run the following commands to build the application from within the `resnet18-app/` folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- The C compiler identification is GNU 5.4.0\n",
      "-- The CXX compiler identification is GNU 5.4.0\n",
      "-- Check for working C compiler: /usr/bin/cc\n",
      "-- Check for working C compiler: /usr/bin/cc -- works\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++\n",
      "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- Looking for pthread.h\n",
      "-- Looking for pthread.h - found\n",
      "-- Looking for pthread_create\n",
      "-- Looking for pthread_create - not found\n",
      "-- Looking for pthread_create in pthreads\n",
      "-- Looking for pthread_create in pthreads - not found\n",
      "-- Looking for pthread_create in pthread\n",
      "-- Looking for pthread_create in pthread - found\n",
      "-- Found Threads: TRUE  \n",
      "-- Found torch: /home/ubuntu/development/pytorch-lite/libtorch/lib/libtorch.so  \n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/ubuntu/development/pytorch-lite/notebooks/resnet18-app\n"
     ]
    }
   ],
   "source": [
    "!cmake -DCMAKE_PREFIX_PATH=../../libtorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 45812\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu    13002 May 11 02:43 CMakeCache.txt\r\n",
      "drwxrwxr-x 5 ubuntu ubuntu     4096 May 11 02:43 CMakeFiles\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu     1431 May 11 02:43 cmake_install.cmake\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu      260 May 10 18:16 CMakeLists.txt\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu    11696 May 11 02:43 CPP_Export.ipynb\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu     5145 May 11 02:43 Makefile\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu 46857749 May 11 02:27 model.pt\r\n",
      "-rw-rw-r-- 1 ubuntu ubuntu      468 May 11 02:30 resnet18-app.cpp\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mScanning dependencies of target resnet18-app\u001b[0m\n",
      "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/resnet18-app.dir/resnet18-app.cpp.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX executable resnet18-app\u001b[0m\n",
      "[100%] Built target resnet18-app\n"
     ]
    }
   ],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rwxrwxr-x 1 ubuntu ubuntu 83320 May 11 02:44 resnet18-app\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l resnet18-app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we supply the path to the serialized `ResNet18` model we created earlier to the resulting `resnet18-app` binary, we should be rewarded with a friendly \"ok\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: example-app <path-to-exported-script-module>\r\n"
     ]
    }
   ],
   "source": [
    "!./resnet18-app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\r\n"
     ]
    }
   ],
   "source": [
    "!./resnet18-app model.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Executing the Script Module in C++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having successfully loaded our serialized `ResNet18` in C++, we are now just a couple lines of code away from executing it! Let’s add those lines to our C++ application’s `main()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#include <torch/script.h> // One-stop header.\r\n",
      "\r\n",
      "#include <iostream>\r\n",
      "#include <memory>\r\n",
      "\r\n",
      "int main(int argc, const char* argv[]) {\r\n",
      "    if (argc != 2) {\r\n",
      "        std::cerr << \"usage: example-app <path-to-exported-script-module>\\n\";\r\n",
      "        return -1;\r\n",
      "    }\r\n",
      "\r\n",
      "    // Deserialize the ScriptModule from a file using torch::jit::load().\r\n",
      "    std::shared_ptr<torch::jit::script::Module> module = torch::jit::load(argv[1]);\r\n",
      "\r\n",
      "    assert(module != nullptr);\r\n",
      "    std::cout << \"ok\\n\";\r\n",
      "\r\n",
      "    // Create a vector of inputs.\r\n",
      "    std::vector<torch::jit::IValue> inputs;\r\n",
      "    inputs.push_back(torch::ones({1, 3, 224, 224}));\r\n",
      "\r\n",
      "    // Execute the model and turn its output into a tensor.\r\n",
      "    at::Tensor output = module->forward(inputs).toTensor();\r\n",
      "\r\n",
      "    std::cout << output.slice(/*dim=*/1, /*start=*/0, /*end=*/5) << '\\n';\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat resnet18-app.cpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s try it out by re-compiling our application and running it with the same serialized model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mScanning dependencies of target resnet18-app\u001b[0m\n",
      "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/resnet18-app.dir/resnet18-app.cpp.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX executable resnet18-app\u001b[0m\n",
      "[100%] Built target resnet18-app\n"
     ]
    }
   ],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      " 0.0808  0.5042  0.7030 -0.9465  0.4538\n",
      "[ Variable[CPUFloatType]{1,5} ]\n"
     ]
    }
   ],
   "source": [
    "!./resnet18-app model.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, the output in Python previously was:\n",
    "\n",
    "```sh\n",
    "tensor([ 0.0808,  0.5042,  0.7030, -0.9465,  0.4538], grad_fn=<SliceBackward>)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a good match!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Getting Help and Exploring the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial has hopefully equipped you with a general understanding of a PyTorch model’s path from Python to C++. With the concepts described in this tutorial, you should be able to go from a vanilla, “eager” PyTorch model, to a compiled `ScriptModule` in Python, to a serialized file on disk and – to close the loop – to an executable `script::Module` in C++.\n",
    "\n",
    "Of course, there are many concepts we did not cover. To learn more, go to: https://pytorch.org/tutorials/advanced/cpp_export.html#step-5-getting-help-and-exploring-the-api"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
